{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ddkaba/IAD_Lab_2/blob/main/IAD_Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCXwWZbElzuB"
      },
      "source": [
        "Группа 4232\n",
        "\n",
        "Спицов А.\n",
        "\n",
        "Михайлов Д.\n",
        "\n",
        "Вариант №2 (Анализ вин по трем производителям)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnUK3aahlY4P"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, classification_report\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hn6jx2eymNks"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/Ddkaba/IAD_Lab_2/main/V2_classification_lr3.csv\", index_col=0)\n",
        "if 'No' in dataset.columns:\n",
        "    dataset = dataset.drop(columns=['No'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljSLcSkZpQUA",
        "outputId": "7abe75c8-cbc9-48dc-b70b-b7bd6518a1bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Общая информация\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 178 entries, 14.23 to 14.13\n",
            "Data columns (total 13 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   malic_acid                    178 non-null    float64\n",
            " 1   ash                           178 non-null    float64\n",
            " 2   alcalinity_of_ash             178 non-null    float64\n",
            " 3   magnesium                     178 non-null    float64\n",
            " 4   total_phenols                 178 non-null    float64\n",
            " 5   flavanoids                    178 non-null    float64\n",
            " 6   nonflavanoid_phenols          178 non-null    float64\n",
            " 7   proanthocyanins               178 non-null    float64\n",
            " 8   color_intensity               178 non-null    float64\n",
            " 9   hue                           178 non-null    float64\n",
            " 10  od280/od315_of_diluted_wines  178 non-null    float64\n",
            " 11  proline                       178 non-null    float64\n",
            " 12  target                        178 non-null    int64  \n",
            "dtypes: float64(12), int64(1)\n",
            "memory usage: 19.5 KB\n",
            "None\n",
            "Количество записей (объектов): 178\n",
            "Количество признаков (фич): 13\n",
            "\n",
            "Названия столбцов:\n",
            "['malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline', 'target']\n",
            "\n",
            "Типы данных:\n",
            "malic_acid                      float64\n",
            "ash                             float64\n",
            "alcalinity_of_ash               float64\n",
            "magnesium                       float64\n",
            "total_phenols                   float64\n",
            "flavanoids                      float64\n",
            "nonflavanoid_phenols            float64\n",
            "proanthocyanins                 float64\n",
            "color_intensity                 float64\n",
            "hue                             float64\n",
            "od280/od315_of_diluted_wines    float64\n",
            "proline                         float64\n",
            "target                            int64\n",
            "dtype: object\n",
            "\n",
            "Пропущенные значения:\n",
            "malic_acid                      0\n",
            "ash                             0\n",
            "alcalinity_of_ash               0\n",
            "magnesium                       0\n",
            "total_phenols                   0\n",
            "flavanoids                      0\n",
            "nonflavanoid_phenols            0\n",
            "proanthocyanins                 0\n",
            "color_intensity                 0\n",
            "hue                             0\n",
            "od280/od315_of_diluted_wines    0\n",
            "proline                         0\n",
            "target                          0\n",
            "dtype: int64\n",
            "Общее количество пропущенных значений: 0\n",
            "Целевая переменная\n",
            "\n",
            "Целевая переменная: target\n",
            "Тип данных целевой переменной: int64\n",
            "Уникальные значения целевой переменной (первые 20): [0 1 2]\n",
            "Всего уникальных значений: 3\n",
            "Распределение классов:\n",
            "target\n",
            "1    71\n",
            "0    59\n",
            "2    48\n",
            "Name: count, dtype: int64\n",
            "Процентное соотношение классов:\n",
            "target\n",
            "1    39.887640\n",
            "0    33.146067\n",
            "2    26.966292\n",
            "Name: proportion, dtype: float64\n",
            "Статистика\n",
            "       malic_acid         ash  alcalinity_of_ash   magnesium  total_phenols  \\\n",
            "count  178.000000  178.000000         178.000000  178.000000     178.000000   \n",
            "mean     2.336348    2.366517          19.494944   99.741573       2.295112   \n",
            "std      1.117146    0.274344           3.339564   14.282484       0.625851   \n",
            "min      0.740000    1.360000          10.600000   70.000000       0.980000   \n",
            "25%      1.602500    2.210000          17.200000   88.000000       1.742500   \n",
            "50%      1.865000    2.360000          19.500000   98.000000       2.355000   \n",
            "75%      3.082500    2.557500          21.500000  107.000000       2.800000   \n",
            "max      5.800000    3.230000          30.000000  162.000000       3.880000   \n",
            "\n",
            "       flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity  \\\n",
            "count  178.000000            178.000000       178.000000       178.000000   \n",
            "mean     2.029270              0.361854         1.590899         5.058090   \n",
            "std      0.998859              0.124453         0.572359         2.318286   \n",
            "min      0.340000              0.130000         0.410000         1.280000   \n",
            "25%      1.205000              0.270000         1.250000         3.220000   \n",
            "50%      2.135000              0.340000         1.555000         4.690000   \n",
            "75%      2.875000              0.437500         1.950000         6.200000   \n",
            "max      5.080000              0.660000         3.580000        13.000000   \n",
            "\n",
            "              hue  od280/od315_of_diluted_wines      proline      target  \n",
            "count  178.000000                    178.000000   178.000000  178.000000  \n",
            "mean     0.957449                      2.611685   746.893258    0.938202  \n",
            "std      0.228572                      0.709990   314.907474    0.775035  \n",
            "min      0.480000                      1.270000   278.000000    0.000000  \n",
            "25%      0.782500                      1.937500   500.500000    0.000000  \n",
            "50%      0.965000                      2.780000   673.500000    1.000000  \n",
            "75%      1.120000                      3.170000   985.000000    2.000000  \n",
            "max      1.710000                      4.000000  1680.000000    2.000000  \n",
            "Анализ кат. признаков\n",
            "target: 3 уникальных значений - [0 1 2]\n",
            "\n",
            "Всего категориальных признаков: 1\n",
            "Корреляции признаков с целевой переменной:\n",
            "alcalinity_of_ash               0.517859\n",
            "nonflavanoid_phenols            0.489109\n",
            "malic_acid                      0.437776\n",
            "color_intensity                 0.265668\n",
            "ash                            -0.049643\n",
            "magnesium                      -0.209179\n",
            "proanthocyanins                -0.499130\n",
            "hue                            -0.617369\n",
            "proline                        -0.633717\n",
            "total_phenols                  -0.719163\n",
            "od280/od315_of_diluted_wines   -0.788230\n",
            "flavanoids                     -0.847498\n",
            "Name: target, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "TARGET = 'target'\n",
        "\n",
        "print(\"Общая информация\")\n",
        "print(dataset.info())\n",
        "\n",
        "print(f\"Количество записей (объектов): {dataset.shape[0]}\")\n",
        "print(f\"Количество признаков (фич): {dataset.shape[1]}\")\n",
        "\n",
        "print(\"\\nНазвания столбцов:\")\n",
        "print(dataset.columns.tolist())\n",
        "\n",
        "print(\"\\nТипы данных:\")\n",
        "print(dataset.dtypes)\n",
        "\n",
        "print(\"\\nПропущенные значения:\")\n",
        "missing_values = dataset.isnull().sum()\n",
        "print(missing_values)\n",
        "print(f\"Общее количество пропущенных значений: {missing_values.sum()}\")\n",
        "\n",
        "print(\"Целевая переменная\")\n",
        "if TARGET in dataset.columns:\n",
        "    print(f\"\\nЦелевая переменная: {TARGET}\")\n",
        "    print(f\"Тип данных целевой переменной: {dataset[TARGET].dtype}\")\n",
        "    unique_values = dataset[TARGET].unique()\n",
        "    print(f\"Уникальные значения целевой переменной (первые 20): {unique_values[:20]}\")\n",
        "    print(f\"Всего уникальных значений: {unique_values.size}\")\n",
        "    if dataset[TARGET].nunique() <= 20:\n",
        "        print(\"Распределение классов:\")\n",
        "        print(dataset[TARGET].value_counts())\n",
        "        print(\"Процентное соотношение классов:\")\n",
        "        print(dataset[TARGET].value_counts(normalize=True) * 100)\n",
        "\n",
        "print(\"Статистика\")\n",
        "print(dataset.describe())\n",
        "\n",
        "print(\"Анализ кат. признаков\")\n",
        "categorical_features = []\n",
        "for col in dataset.columns:\n",
        "    unique_values = dataset[col].nunique(dropna=True)\n",
        "    if unique_values <= 10:\n",
        "        categorical_features.append(col)\n",
        "        print(f\"{col}: {unique_values} уникальных значений - {dataset[col].unique()}\")\n",
        "\n",
        "print(f\"\\nВсего категориальных признаков: {len(categorical_features)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Корреляционная матрица для Wine датасета\n",
        "correlation_matrix = dataset.corr(numeric_only=True)\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
        "plt.title('Корреляционная матрица признаков Wine')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Гистограммы по всем числовым признакам\n",
        "# Определим список числовых колонок и исключим целевую, если она есть\n",
        "feature_columns = dataset.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if 'target' in feature_columns:\n",
        "    feature_columns.remove('target')\n",
        "\n",
        "_ = dataset[feature_columns].hist(\n",
        "    bins=10,\n",
        "    figsize=(20, 15),\n",
        "    grid=False,\n",
        "    edgecolor='black'\n",
        ")\n",
        "plt.suptitle('Распределение числовых признаков', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_original = dataset.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Использование SelectKBest для оценки информативности признаков и выбора топ-5 (Wine)\n",
        "source_df = dataset\n",
        "\n",
        "# Числовые признаки\n",
        "X_num = source_df.drop(columns=[TARGET]).select_dtypes(include=[np.number])\n",
        "y = source_df[TARGET]\n",
        "\n",
        "# Импутация оставшихся пропусков медианой (на всякий случай)\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_num_imp = pd.DataFrame(imputer.fit_transform(X_num), columns=X_num.columns, index=X_num.index)\n",
        "\n",
        "# Для классификации используем f_classif\n",
        "all_selector = SelectKBest(score_func=f_classif, k='all')\n",
        "all_selector.fit(X_num_imp, y)\n",
        "\n",
        "# Результаты\n",
        "scores_df = (\n",
        "    pd.DataFrame({'feature': X_num_imp.columns, 'score': all_selector.scores_})\n",
        "      .sort_values('score', ascending=False)\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "print('Оценки информативности (f_classif), по убыванию:')\n",
        "print(scores_df)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=scores_df, x='score', y='feature', color='#1f77b4')\n",
        "plt.title('SelectKBest: f_classif scores (Wine)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Выбор ТОП-K признаков\n",
        "K = 5\n",
        "selector = SelectKBest(score_func=f_classif, k=K)\n",
        "selector.fit(X_num_imp, y)\n",
        "selected_features = X_num_imp.columns[selector.get_support()].tolist()\n",
        "print(f'Топ-{K} признаков:')\n",
        "print(selected_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Инженерия признаков для Wine: доля флавоноидов в общих фенолах\n",
        "EPS = 1e-9\n",
        "dataset['flavonoid_share'] = dataset['flavanoids'] / (dataset['total_phenols'] + EPS)\n",
        "\n",
        "# Проверка наличия целевой переменной в корреляционной матрице и вывод топ-корреляций\n",
        "corr = dataset.corr()\n",
        "if TARGET in corr.columns:\n",
        "    print('\\nТоп корреляций с целевой переменной:')\n",
        "    print(corr[TARGET].sort_values(ascending=False).head(15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Удаление нерелевантных признаков: ash и magnesium, затем корреляционная матрица\n",
        "cols_to_drop = ['ash', 'magnesium']\n",
        "actual_drop = [c for c in cols_to_drop if c in dataset.columns]\n",
        "print('Удаляем признаки:', actual_drop)\n",
        "\n",
        "dataset = dataset.drop(columns=actual_drop)\n",
        "print('После удаления:', dataset.shape)\n",
        "print('Текущие столбцы:')\n",
        "print(dataset.columns.tolist())\n",
        "\n",
        "df_engineered = dataset.copy()\n",
        "\n",
        "# Корреляционная матрица после удаления\n",
        "correlation_matrix = dataset.corr(numeric_only=True)\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
        "plt.title('Корреляционная матрица после удаления (Wine)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Стандартизация числовых признаков (z = (x - mean) / std) для Wine\n",
        "\n",
        "# Базовые датафреймы\n",
        "base_df = df_original\n",
        "engineered_df = df_engineered\n",
        "\n",
        "def standardize_features(dataset, target):\n",
        "    \"\"\"\n",
        "    Стандартизирует числовые признаки (кроме целевой) и возвращает датафрейм с целевой.\n",
        "    \"\"\"\n",
        "    if target not in dataset.columns:\n",
        "        raise ValueError(f\"Целевая переменная '{target}' отсутствует в датасете.\")\n",
        "\n",
        "    local_df = dataset.copy()\n",
        "    feature_cols = local_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if target in feature_cols:\n",
        "        feature_cols.remove(target)\n",
        "    if not feature_cols:\n",
        "        raise ValueError(\"В датасете нет числовых признаков для стандартизации.\")\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaled = scaler.fit_transform(local_df[feature_cols])\n",
        "    standardized_df = pd.DataFrame(scaled, columns=feature_cols, index=local_df.index)\n",
        "\n",
        "    df_preprocessed = standardized_df.join(local_df[[target]])\n",
        "\n",
        "    print('Стандартизированы признаки:', feature_cols)\n",
        "    print('Форма:', standardized_df.shape)\n",
        "    means = standardized_df.mean().round(4)\n",
        "    stdevs = standardized_df.std(ddof=0).round(4)\n",
        "    print('\\nСредние по столбцам (ожид. ≈ 0):')\n",
        "    print(means)\n",
        "    print('\\nСт. отклонения (ожид. ≈ 1):')\n",
        "    print(stdevs)\n",
        "    print('\\n')\n",
        "\n",
        "    return df_preprocessed\n",
        "\n",
        "df_original_preprocessed = standardize_features(base_df, TARGET)\n",
        "df_engineered_preprocessed = standardize_features(engineered_df, TARGET)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/Validation/Test split: 60% / 20% / 20%\n",
        "\n",
        "# Источник данных: используем расширенный набор\n",
        "src = dataset if 'dataset' in globals() else dataset\n",
        "\n",
        "X = src.drop(columns=[TARGET])\n",
        "y = src[TARGET]\n",
        "\n",
        "# 1) Test split (20%)\n",
        "seed = 42\n",
        "test_size = 0.2\n",
        "val_size = 0.25  # 25% от train -> итог 60/20/20\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=test_size, random_state=seed\n",
        ")\n",
        "\n",
        "# 2) Validation split из обучающей части\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=val_size, random_state=seed\n",
        ")\n",
        "\n",
        "print('Shapes:')\n",
        "print('X_train:', X_train.shape, 'X_val:', X_val.shape, 'X_test:', X_test.shape)\n",
        "print('y_train:', y_train.shape, 'y_val:', y_val.shape, 'y_test:', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Общая информация\")\n",
        "print(df_original.info())\n",
        "print('\\n')\n",
        "print(df_engineered.info())\n",
        "print('\\n')\n",
        "print(df_original_preprocessed.info())\n",
        "print('\\n')\n",
        "print(df_engineered_preprocessed.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сравнение MLP-классификатора и SimpleRNN-классификатора на train/val для наборов:\n",
        "# df_original, df_engineered_preprocessed, df_original_preprocessed, df_engineered\n",
        "keras = tf.keras\n",
        "\n",
        "# Фиксируем seed для воспроизводимости эксперимента\n",
        "np.random.seed(42)\n",
        "try:\n",
        "    tf.random.set_seed(42)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "\n",
        "# Проверяем, что данные уже разделены на train/val (иначе прерываем выполнение)\n",
        "assert 'X_train' in globals() and 'X_val' in globals(), 'Сначала запустите ячейку с train/val/test split.'\n",
        "train_idx = X_train.index\n",
        "val_idx = X_val.index\n",
        "\n",
        "# Составляем словарь доступных датасетов для тестирования\n",
        "datasets_map = {}\n",
        "if 'df_original' in globals():\n",
        "    datasets_map['df_original'] = df_original.copy()\n",
        "if 'df_engineered_preprocessed' in globals():\n",
        "    datasets_map['df_engineered_preprocessed'] = df_engineered_preprocessed.copy()\n",
        "if 'df_original_preprocessed' in globals():\n",
        "    datasets_map['df_original_preprocessed'] = df_original_preprocessed.copy()\n",
        "if 'df_engineered' in globals():\n",
        "    datasets_map['df_engineered'] = df_engineered.copy()\n",
        "\n",
        "assert len(datasets_map) > 0, 'Нет доступных датафреймов из списка.'\n",
        "\n",
        "results = []\n",
        "\n",
        "num_classes = int(dataset[TARGET].nunique())\n",
        "reg = tf.keras.regularizers.l2(1e-4)\n",
        "\n",
        "# Проходим по каждому датасету\n",
        "for name, df in datasets_map.items():\n",
        "    # Берем только числовые признаки\n",
        "    X_all = df.drop(columns=[TARGET]).select_dtypes(include=[np.number])\n",
        "    y_all = df[TARGET].astype(int)\n",
        "\n",
        "    # Разделение на train/val по заранее сохранённым индексам\n",
        "    X_tr = X_all.loc[train_idx]\n",
        "    y_tr = y_all.loc[train_idx]\n",
        "    X_va = X_all.loc[val_idx]\n",
        "    y_va = y_all.loc[val_idx]\n",
        "\n",
        "    # Class weights (на train)\n",
        "    classes = np.unique(y_tr)\n",
        "    cw = compute_class_weight(class_weight='balanced', classes=classes, y=y_tr)\n",
        "    class_weight = {int(c): float(w) for c, w in zip(classes, cw)}\n",
        "\n",
        "    # Препроцессинг: не стандартизируем повторно *_preprocessed\n",
        "    is_preprocessed = name.endswith('_preprocessed')\n",
        "    if is_preprocessed:\n",
        "        X_tr_std = X_tr.values\n",
        "        X_va_std = X_va.values\n",
        "    else:\n",
        "        imputer = SimpleImputer(strategy='median')\n",
        "        scaler = StandardScaler()\n",
        "        X_tr_imp = imputer.fit_transform(X_tr)\n",
        "        X_va_imp = imputer.transform(X_va)\n",
        "        X_tr_std = scaler.fit_transform(X_tr_imp)\n",
        "        X_va_std = scaler.transform(X_va_imp)\n",
        "\n",
        "    input_dim = X_tr_std.shape[1]\n",
        "\n",
        "    # Callbacks\n",
        "    es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "    rlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
        "\n",
        "    # Полносвязная классификационная модель (MLP) с Dropout+L2\n",
        "    mlp = keras.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(64, activation='relu', kernel_regularizer=reg),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu', kernel_regularizer=reg),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    mlp.compile(optimizer=keras.optimizers.Adam(1e-3), loss='sparse_categorical_crossentropy')\n",
        "    mlp.fit(X_tr_std, y_tr.values, validation_data=(X_va_std, y_va.values),\n",
        "            epochs=200, batch_size=32, verbose=0, callbacks=[es, rlrop], class_weight=class_weight)\n",
        "\n",
        "    # Предсказания (классы) для MLP\n",
        "    y_tr_prob = mlp.predict(X_tr_std, verbose=0)\n",
        "    y_va_prob = mlp.predict(X_va_std, verbose=0)\n",
        "    y_tr_pred = y_tr_prob.argmax(axis=1)\n",
        "    y_va_pred = y_va_prob.argmax(axis=1)\n",
        "\n",
        "    # Метрики MLP\n",
        "    acc_tr = accuracy_score(y_tr, y_tr_pred)\n",
        "    acc_va = accuracy_score(y_va, y_va_pred)\n",
        "    bacc_tr = balanced_accuracy_score(y_tr, y_tr_pred)\n",
        "    bacc_va = balanced_accuracy_score(y_va, y_va_pred)\n",
        "    f1_micro_tr = f1_score(y_tr, y_tr_pred, average='micro')\n",
        "    f1_micro_va = f1_score(y_va, y_va_pred, average='micro')\n",
        "    f1_macro_tr = f1_score(y_tr, y_tr_pred, average='macro')\n",
        "    f1_macro_va = f1_score(y_va, y_va_pred, average='macro')\n",
        "    f1_weighted_tr = f1_score(y_tr, y_tr_pred, average='weighted')\n",
        "    f1_weighted_va = f1_score(y_va, y_va_pred, average='weighted')\n",
        "\n",
        "    results.append({\n",
        "        'dataset': name,\n",
        "        'model': 'MLP-Classifier',\n",
        "        'acc_train': acc_tr,\n",
        "        'acc_val': acc_va,\n",
        "        'bal_acc_train': bacc_tr,\n",
        "        'bal_acc_val': bacc_va,\n",
        "        'f1_micro_train': f1_micro_tr,\n",
        "        'f1_micro_val': f1_micro_va,\n",
        "        'f1_macro_train': f1_macro_tr,\n",
        "        'f1_macro_val': f1_macro_va,\n",
        "        'f1_weighted_train': f1_weighted_tr,\n",
        "        'f1_weighted_val': f1_weighted_va,\n",
        "    })\n",
        "\n",
        "    print(f\"\\n=== Классификация (MLP): {name} ===\")\n",
        "    print('Validation classification report:')\n",
        "    print(classification_report(y_va, y_va_pred, digits=4))\n",
        "\n",
        "    # SimpleRNN классификатор с dropout\n",
        "    X_tr_seq = X_tr_std.reshape((-1, input_dim, 1))\n",
        "    X_va_seq = X_va_std.reshape((-1, input_dim, 1))\n",
        "\n",
        "    rnn = keras.Sequential([\n",
        "        layers.Input(shape=(input_dim, 1)),\n",
        "        layers.SimpleRNN(32, activation='tanh', dropout=0.2, recurrent_dropout=0.2),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    rnn.compile(optimizer=keras.optimizers.Adam(1e-3), loss='sparse_categorical_crossentropy')\n",
        "    rnn.fit(X_tr_seq, y_tr.values, validation_data=(X_va_seq, y_va.values),\n",
        "            epochs=200, batch_size=32, verbose=0, callbacks=[es, rlrop], class_weight=class_weight)\n",
        "\n",
        "    # Предсказания (классы) для RNN\n",
        "    y_tr_prob_rnn = rnn.predict(X_tr_seq, verbose=0)\n",
        "    y_va_prob_rnn = rnn.predict(X_va_seq, verbose=0)\n",
        "    y_tr_pred_rnn = y_tr_prob_rnn.argmax(axis=1)\n",
        "    y_va_pred_rnn = y_va_prob_rnn.argmax(axis=1)\n",
        "\n",
        "    # Метрики RNN\n",
        "    acc_tr_rnn = accuracy_score(y_tr, y_tr_pred_rnn)\n",
        "    acc_va_rnn = accuracy_score(y_va, y_va_pred_rnn)\n",
        "    bacc_tr_rnn = balanced_accuracy_score(y_tr, y_tr_pred_rnn)\n",
        "    bacc_va_rnn = balanced_accuracy_score(y_va, y_va_pred_rnn)\n",
        "    f1_micro_tr_rnn = f1_score(y_tr, y_tr_pred_rnn, average='micro')\n",
        "    f1_micro_va_rnn = f1_score(y_va, y_va_pred_rnn, average='micro')\n",
        "    f1_macro_tr_rnn = f1_score(y_tr, y_tr_pred_rnn, average='macro')\n",
        "    f1_macro_va_rnn = f1_score(y_va, y_va_pred_rnn, average='macro')\n",
        "    f1_weighted_tr_rnn = f1_score(y_tr, y_tr_pred_rnn, average='weighted')\n",
        "    f1_weighted_va_rnn = f1_score(y_va, y_va_pred_rnn, average='weighted')\n",
        "\n",
        "    results.append({\n",
        "        'dataset': name,\n",
        "        'model': 'SimpleRNN-Classifier',\n",
        "        'acc_train': acc_tr_rnn,\n",
        "        'acc_val': acc_va_rnn,\n",
        "        'bal_acc_train': bacc_tr_rnn,\n",
        "        'bal_acc_val': bacc_va_rnn,\n",
        "        'f1_micro_train': f1_micro_tr_rnn,\n",
        "        'f1_micro_val': f1_micro_va_rnn,\n",
        "        'f1_macro_train': f1_macro_tr_rnn,\n",
        "        'f1_macro_val': f1_macro_va_rnn,\n",
        "        'f1_weighted_train': f1_weighted_tr_rnn,\n",
        "        'f1_weighted_val': f1_weighted_va_rnn,\n",
        "    })\n",
        "\n",
        "    print(f\"\\n=== Классификация (SimpleRNN): {name} ===\")\n",
        "    print('Validation classification report:')\n",
        "    print(classification_report(y_va, y_va_pred_rnn, digits=4))\n",
        "\n",
        "# Итоговая таблица результатов\n",
        "res_df = pd.DataFrame(results)\n",
        "print('\\nСводная таблица по метрикам (train/val):')\n",
        "print(res_df.sort_values(['dataset', 'model']).to_string(index=False))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
